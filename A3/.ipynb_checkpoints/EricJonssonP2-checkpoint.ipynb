{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "middle-neighborhood",
   "metadata": {},
   "source": [
    "# PART B\n",
    "(Or better known as part B: Thank god for abstractions)\n",
    "### CONFIGURATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "lyric-startup",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark_session = SparkSession\\\n",
    "        .builder\\\n",
    "        .master(\"spark://192.168.2.113:7077\") \\\n",
    "        .appName(\"EricJonsson_B\")\\\n",
    "        .config(\"spark.dynamicAllocation.enabled\", True)\\\n",
    "        .config(\"spark.shuffle.service.enabled\", True)\\\n",
    "        .config(\"spark.dynamicAllocation.executorIdleTimeout\",\"30s\")\\\n",
    "        .config(\"spark.executor.cores\",2)\\\n",
    "        .config(\"spark.driver.port\",9998)\\\n",
    "        .config(\"spark.blockManager.port\",10005)\\\n",
    "        .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gothic-practitioner",
   "metadata": {},
   "source": [
    "### B.1 - B.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "neither-organ",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------------+----------+--------+-----------+--------------+-----------------+----+----+----------+-----+--------------------+-----+------+--------------+---------------------+-----------+---------+---------+\n",
      "|Ticket number|         Issue Date|Issue time|Meter Id|Marked Time|RP State Plate|Plate Expiry Date| VIN|Make|Body Style|Color|            Location|Route|Agency|Violation code|Violation Description|Fine amount| Latitude|Longitude|\n",
      "+-------------+-------------------+----------+--------+-----------+--------------+-----------------+----+----+----------+-----+--------------------+-----+------+--------------+---------------------+-----------+---------+---------+\n",
      "|   1103341116|2015-12-21T00:00:00|      1251|    null|       null|            CA|           200304|null|HOND|        PA|   GY|     13147 WELBY WAY|01521|     1|        4000A1|   NO EVIDENCE OF REG|         50|    99999|    99999|\n",
      "|   1103700150|2015-12-21T00:00:00|      1435|    null|       null|            CA|           201512|null| GMC|        VN|   WH|       525 S MAIN ST| 1C51|     1|        4000A1|   NO EVIDENCE OF REG|         50|    99999|    99999|\n",
      "|   1104803000|2015-12-21T00:00:00|      2055|    null|       null|            CA|           201503|null|NISS|        PA|   BK|       200 WORLD WAY|  2R2|     2|          8939|           WHITE CURB|         58|6439997.9|1802686.4|\n",
      "|   1104820732|2015-12-26T00:00:00|      1515|    null|       null|            CA|             null|null|ACUR|        PA|   WH|       100 WORLD WAY| 2F11|     2|           000|               17104h|       null|6440041.1|1802686.2|\n",
      "|   1105461453|2015-09-15T00:00:00|       115|    null|       null|            CA|           200316|null|CHEV|        PA|   BK|  GEORGIA ST/OLYMPIC|1FB70|     1|         8069A| NO STOPPING/STANDING|         93|    99999|    99999|\n",
      "|   1106226590|2015-09-15T00:00:00|        19|    null|       null|            CA|           201507|null|CHEV|        VN|   GY|  SAN PEDRO S/O BOYD|1A35W|     1|        4000A1|   NO EVIDENCE OF REG|         50|    99999|    99999|\n",
      "|   1106500452|2015-12-17T00:00:00|      1710|    null|       null|            CA|           201605|null|MAZD|        PA|   BL|     SUNSET/ALVARADO|00217|     1|          8070| PARK IN GRID LOCK ZN|        163|    99999|    99999|\n",
      "|   1106500463|2015-12-17T00:00:00|      1710|    null|       null|            CA|           201602|null|TOYO|        PA|   BK|     SUNSET/ALVARADO|00217|     1|          8070| PARK IN GRID LOCK ZN|        163|    99999|    99999|\n",
      "|   1106506402|2015-12-22T00:00:00|       945|    null|       null|            CA|           201605|null|CHEV|        PA|   BR|      721 S WESTLAKE| 2A75|     1|        8069AA|     NO STOP/STAND AM|         93|    99999|    99999|\n",
      "|   1106506413|2015-12-22T00:00:00|      1100|    null|       null|            CA|           201701|null|NISS|        PA|   SI|     1159 HUNTLEY DR| 2A75|     1|        8069AA|     NO STOP/STAND AM|         93|    99999|    99999|\n",
      "|   1106506424|2015-12-22T00:00:00|      1100|    null|       null|            CA|           201511|null|FORD|        TR|   WH|     1159 HUNTLEY DR| 2A75|     1|        8069AA|     NO STOP/STAND AM|         93|    99999|    99999|\n",
      "|   1106506435|2015-12-22T00:00:00|      1105|    null|       null|            CA|           201701|null|CHRY|        PA|   GO|     1159 HUNTLEY DR| 2A75|     1|        8069AA|     NO STOP/STAND AM|         93|    99999|    99999|\n",
      "|   1106506446|2015-12-22T00:00:00|      1110|    null|       null|            CA|           201511|null| BMW|        PA|   BK|      1200 W MIRAMAR| 2A75|     1|        4000A1|   NO EVIDENCE OF REG|         50|    99999|    99999|\n",
      "|   1106549754|2015-12-15T00:00:00|       825|    null|       null|            CA|           201607|null|PTRB|        TR|   BK|           4TH/STATE| CM96|     1|         8069A| NO STOPPING/STANDING|         93|    99999|    99999|\n",
      "|   1107179581|2015-12-27T00:00:00|      1055|    null|       null|            CA|           201605|null|TOYO|        PA|   BK|3100 N HOLLYRIDGE DR| null|    54|         8058L|         PREF PARKING|         68|    99999|    99999|\n",
      "|   1107179592|2015-12-27T00:00:00|      1200|    null|       null|            CA|           201602|null|MBNZ|        PA|   BK|   3115 N BERENDO DR| null|    54|         8058L|         PREF PARKING|         68|    99999|    99999|\n",
      "|   1107179603|2015-12-27T00:00:00|      1400|    null|       null|            CA|           201611|null|NISS|        PA|   WH| 3100 N BEACHWOOD DR| null|    54|         8058L|         PREF PARKING|         68|    99999|    99999|\n",
      "|   1107539823|2015-09-16T00:00:00|      2120|    null|       null|            CA|           201502|null|NISS|        PA| null|      BLAINE/11TH PL|1FB95|     1|        4000A1|   NO EVIDENCE OF REG|         50|    99999|    99999|\n",
      "|   1107539834|2015-09-16T00:00:00|      1045|    null|       null|            CA|             null|null|CHEV|        PA|   BK|  1246 S FIGUEROA ST| 1L20|     1|        8069AP|     NO STOP/STAND PM|         93|    99999|    99999|\n",
      "|   1107780811|2015-12-22T00:00:00|      1102|    null|       null|            CA|           201606|null|HOND|        PA|   BK|       PLATA/RAMPART|  2A1|     1|         8069B|           NO PARKING|         73|    99999|    99999|\n",
      "+-------------+-------------------+----------+--------+-----------+--------------+-----------------+----+----+----------+-----+--------------------+-----+------+--------------+---------------------+-----------+---------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# B.1\n",
    "\n",
    "# Load CSV file\n",
    "citations_original_df = spark_session.read\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .csv('hdfs://192.168.2.113:9000/parking-citations.csv')\\\n",
    "    .cache()\n",
    "# Show Dataframe\n",
    "citations_original_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "funky-conversion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Ticket number: string (nullable = true)\n",
      " |-- Issue Date: string (nullable = true)\n",
      " |-- Issue time: string (nullable = true)\n",
      " |-- Meter Id: string (nullable = true)\n",
      " |-- Marked Time: string (nullable = true)\n",
      " |-- RP State Plate: string (nullable = true)\n",
      " |-- Plate Expiry Date: string (nullable = true)\n",
      " |-- VIN: string (nullable = true)\n",
      " |-- Make: string (nullable = true)\n",
      " |-- Body Style: string (nullable = true)\n",
      " |-- Color: string (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- Route: string (nullable = true)\n",
      " |-- Agency: string (nullable = true)\n",
      " |-- Violation code: string (nullable = true)\n",
      " |-- Violation Description: string (nullable = true)\n",
      " |-- Fine amount: string (nullable = true)\n",
      " |-- Latitude: string (nullable = true)\n",
      " |-- Longitude: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# B.2\n",
    "\n",
    "# Print Schema\n",
    "citations_original_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "sustainable-cuisine",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9257460"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# B.3\n",
    "\n",
    "# Count Number of Rows\n",
    "citations_original_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "technical-enlargement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# B.4\n",
    "\n",
    "# Count number of partitions\n",
    "citations_original_df.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "moved-correspondence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Ticket number: string (nullable = true)\n",
      " |-- Issue Date: string (nullable = true)\n",
      " |-- Issue time: string (nullable = true)\n",
      " |-- Meter Id: string (nullable = true)\n",
      " |-- Marked Time: string (nullable = true)\n",
      " |-- RP State Plate: string (nullable = true)\n",
      " |-- Plate Expiry Date: string (nullable = true)\n",
      " |-- Make: string (nullable = true)\n",
      " |-- Body Style: string (nullable = true)\n",
      " |-- Color: string (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- Route: string (nullable = true)\n",
      " |-- Agency: string (nullable = true)\n",
      " |-- Violation code: string (nullable = true)\n",
      " |-- Violation Description: string (nullable = true)\n",
      " |-- Fine amount: string (nullable = true)\n",
      " |-- Longitude: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# B.5\n",
    "\n",
    "# Drop VIN, Long, Lat\n",
    "citations_df = citations_original_df.drop('VIN', 'Latitude', 'Latitude')\n",
    "# Print Schema after Drop\n",
    "citations_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "acknowledged-cleaner",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Ticket number: string (nullable = true)\n",
      " |-- Issue Date: string (nullable = true)\n",
      " |-- Issue time: string (nullable = true)\n",
      " |-- Meter Id: string (nullable = true)\n",
      " |-- Marked Time: string (nullable = true)\n",
      " |-- RP State Plate: string (nullable = true)\n",
      " |-- Plate Expiry Date: string (nullable = true)\n",
      " |-- Make: string (nullable = true)\n",
      " |-- Body Style: string (nullable = true)\n",
      " |-- Color: string (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- Route: string (nullable = true)\n",
      " |-- Agency: string (nullable = true)\n",
      " |-- Violation code: string (nullable = true)\n",
      " |-- Violation Description: string (nullable = true)\n",
      " |-- Fine amount: float (nullable = true)\n",
      " |-- Longitude: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# B.6\n",
    "\n",
    "from pyspark.sql.types import FloatType\n",
    "\n",
    "# Since dataframes are immutable, we drop the 'Fine amount' column, and create a new dataframe with the same column name but float type\n",
    "citations_converted_df = citations_df.drop('Fine amount')\n",
    "citations_converted_df = citations_df.withColumn('Fine amount', citations_df['Fine amount'].cast(FloatType()))\n",
    "# Print Schema of updated dataframe to verify that the column 'Fine amount' is indeed of type float\n",
    "citations_converted_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "miniature-selection",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+\n",
      "|Fine amount|  count|\n",
      "+-----------+-------+\n",
      "|      505.0|      6|\n",
      "|      363.0|  63366|\n",
      "|      353.0|     15|\n",
      "|      345.0|     40|\n",
      "|      330.0|      1|\n",
      "|      293.0|  10401|\n",
      "|      255.0|     30|\n",
      "|      163.0| 106748|\n",
      "|      155.0|      1|\n",
      "|      143.0|    373|\n",
      "|      133.0|   9185|\n",
      "|      128.0|    338|\n",
      "|      123.0|      3|\n",
      "|      113.0|      2|\n",
      "|      105.0|    729|\n",
      "|      103.0|   7401|\n",
      "|       98.0|    333|\n",
      "|       93.0|1097437|\n",
      "|       88.0|    158|\n",
      "|       85.0|      5|\n",
      "+-----------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# B.6\n",
    "\n",
    "# Group and order by fine amount and show in descending order\n",
    "citations_converted_df.select('Fine amount').groupBy('Fine amount').count().orderBy('Fine amount', ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "weird-schedule",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+\n",
      "|Make|  count|\n",
      "+----+-------+\n",
      "|TOYT|1531949|\n",
      "|HOND|1043276|\n",
      "|FORD| 807498|\n",
      "|NISS| 662097|\n",
      "|CHEV| 631413|\n",
      "| BMW| 422916|\n",
      "|MERZ| 376830|\n",
      "|VOLK| 316002|\n",
      "|HYUN| 285286|\n",
      "|DODG| 271590|\n",
      "|LEXS| 263269|\n",
      "| KIA| 217795|\n",
      "|JEEP| 214965|\n",
      "|AUDI| 179718|\n",
      "|MAZD| 169811|\n",
      "|OTHR| 154376|\n",
      "| GMC| 132788|\n",
      "|INFI| 120340|\n",
      "|CHRY| 120317|\n",
      "|ACUR| 111265|\n",
      "+----+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# B.7\n",
    "\n",
    "# Group by make and order by the count in descending order\n",
    "citations_df.select('Make').groupBy('Make').count().orderBy('count', ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "published-soundtrack",
   "metadata": {},
   "outputs": [],
   "source": [
    "# B.8\n",
    "\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "# Function that returns the long name when given a shorthand color, return the original name if no match is found\n",
    "def colorToLong(col):\n",
    "    COLORS={'AL':'Aluminum','AM':'Amber','BG':'Beige','BK':'Black','BL':'Blue','BN':'Brown','BR':'Brown','BZ':'Bronze','CH':'Charcoal','DK':'Dark','GD':'Gold','GO':'Gold','GN':'Green','GY':'Gray','GT':'Granite','IV':'Ivory','LT':'Light','OL':'Olive','OR':'Orange','MR':'Maroon','PK':'Pink','RD':'Red','RE':'Red','SI':'Silver','SL':'Silver','SM':'Smoke','TN':'Tan','VT':'Violet','WT':'White','WH':'White','YL':'Yellow','YE':'Yellow','UN':'Unknown'}\n",
    "    if col in COLORS:\n",
    "        return COLORS[col]\n",
    "    else:\n",
    "        return col\n",
    "# Create udf version of the function\n",
    "udf_colorToLong = udf(colorToLong,StringType())\n",
    "\n",
    "# Create new dataframe with new column 'Color Long'\n",
    "citations_colorLong_df = citations_df.withColumn('Color Long', udf_colorToLong('Color'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "likely-college",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+\n",
      "|Color Long| count|\n",
      "+----------+------+\n",
      "|      Gray|346822|\n",
      "|     White|304620|\n",
      "|     Black|252199|\n",
      "|    Silver|248685|\n",
      "|      Blue|128051|\n",
      "|       Red| 84175|\n",
      "|     Green| 57627|\n",
      "|      Gold| 30154|\n",
      "|    Maroon| 19882|\n",
      "|       Tan| 17006|\n",
      "|     Beige| 11572|\n",
      "|        OT| 10805|\n",
      "|     Brown|  8466|\n",
      "|    Yellow|  3413|\n",
      "|        PR|  3010|\n",
      "|    Orange|  2527|\n",
      "|   Unknown|  1343|\n",
      "|        TU|  1077|\n",
      "|        CO|   423|\n",
      "|      Pink|    89|\n",
      "+----------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# B.9\n",
    "\n",
    "# Filter to only show Make == TOYT, group by 'Color Long', count and order in descending order\n",
    "citations_colorLong_df.filter(citations_colorLong_df['Make'] == 'TOYT').groupBy('Color Long').count().orderBy('count', ascending=False).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
